{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QYRH4VUw8L9m"
      },
      "source": [
        "from: https://github.com/SadmanSakib93/Stratified-k-fold-cross-validation-Image-classification-keras/blob/master/stratified_K_fold_CV.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gdTY892I7gOi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-11 10:40:15.379199: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-11 10:40:19.473769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuDNA6xw8ngT",
        "outputId": "3949ad37-1348-45ab-d16d-eba8a5e4532b"
      },
      "outputs": [],
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls\n",
        "import sys\n",
        "# This is the path to where in google drive the code is stored!\n",
        "root_path = '/content/drive/My Drive/'\n",
        "sys.path.append(root_path)\n",
        "\"\"\"\n",
        "\n",
        "root_path = '/workspaces/proposal-ta/images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E8wVsnsN8_ZB"
      },
      "outputs": [],
      "source": [
        "### UBAH NAMA FILE MODEL SESUAI PENGUJIAN DI SINI\n",
        "dataset_folder_name = os.path.join(root_path, '')\n",
        "source_files = []\n",
        "class_labels = ['a', 'ba', 'ca', 'da', 'ga', \n",
        "                'ja', 'ka','la','ma', 'na', \n",
        "                'nga', 'nya','pa', 'ra', 'sa', \n",
        "                'ta', 'wa', 'ya']\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "img_rows, img_cols = 120, 120 # input image dimensions\n",
        "train_path = os.path.join(dataset_folder_name, 'train')\n",
        "validation_path = os.path.join(dataset_folder_name, 'validation')\n",
        "test_path = os.path.join(dataset_folder_name, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# augmentasi data\n",
        "# bisa jadi sebelum atau setelah split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hQTAVyDu92QO"
      },
      "outputs": [],
      "source": [
        "def transfer_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Based on the split ratio this function moves some portion of the source folder to destination folder!\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest location\n",
        "\n",
        "    \"\"\"\n",
        "    global source_files\n",
        "    source_files = os.listdir(source)\n",
        "    if(len(source_files) != 0):\n",
        "        transfer_file_numbers = int(len(source_files)*split_rate)\n",
        "        transfer_index = random.sample(\n",
        "            range(0, len(source_files)), transfer_file_numbers)\n",
        "        for each_index in transfer_index:\n",
        "            shutil.move(os.path.join(source, str(source_files[each_index])), os.path.join(\n",
        "                dest, str(source_files[each_index])))\n",
        "\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "\n",
        "\n",
        "def transfer_all_class_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Transfer the files from source to dest for all the classes. This function calls the 'transfer_between_folders' to actually perform the transfer.\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest location\n",
        "\n",
        "    \"\"\"\n",
        "    for label in class_labels:\n",
        "        transfer_between_folders(os.path.join(dataset_folder_name, source, label),\n",
        "                                 os.path.join(\n",
        "                                     dataset_folder_name, dest, label),\n",
        "                                 split_rate)\n",
        "\n",
        "\n",
        "def my_metrics(y_true, y_pred):\n",
        "    \"\"\" Calculate accuracy, precision, and f1 score of the model's prediction with respect to true labels.\n",
        "\n",
        "        Args:\n",
        "            y_true: list/array\n",
        "                All true class labels\n",
        "            y_pred: list/array\n",
        "                All predicted class labels\n",
        "\n",
        "        Returns:\n",
        "            accuracy: float\n",
        "                Accuracy measure of the model\n",
        "            precision: float\n",
        "                Precision measure of the model\n",
        "            f1_Score: float\n",
        "                F1-score measure of the model\n",
        "\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    f1_Score = f1_score(y_true, y_pred, average='weighted')\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1_Score))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fTSdYcqD-IW5"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('test','train', 1.0)\n",
        "#transfer_all_class_between_folders('validation','train', 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9TdfECoaBoja"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('train', 'test', 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HAeKZkmDBuCx"
      },
      "outputs": [],
      "source": [
        "def prepare_name_with_labels(folder_name, dataset_type='train'):\n",
        "    \"\"\" Prepare the file names (X) and the class labels (Y) from folder location of images.\n",
        "\n",
        "        Args:\n",
        "            folder_name: str\n",
        "                Source folder's path\n",
        "\n",
        "    \"\"\"\n",
        "    source_files = os.listdir(os.path.join(dataset_folder_name, dataset_type, folder_name))\n",
        "    y_label = 0\n",
        "    for i in range(len(class_labels)):\n",
        "        if(folder_name == class_labels[i]):\n",
        "            y_label = i\n",
        "    for val in source_files:\n",
        "        X.append(val)\n",
        "        Y.append(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZXi4N1qSBy8A"
      },
      "outputs": [],
      "source": [
        "# Organize file names and class labels in X and Y variables\n",
        "for i in range(len(class_labels)):\n",
        "    prepare_name_with_labels(class_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h3aTsDa5B155"
      },
      "outputs": [],
      "source": [
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8DKyU0MOB3Tj"
      },
      "outputs": [],
      "source": [
        "# arsitektur\n",
        "batch_size = 32\n",
        "epoch = 50\n",
        "num_of_channels = 3\n",
        "number_of_class_labels = len(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1ljNTaGaCIzc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 120, 120, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 118, 118, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 59, 59, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 59, 59, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 59, 59, 32)        18464     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 57, 57, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 26, 26, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 13, 13, 16)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2704)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               346240    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                2322      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 421,938\n",
            "Trainable params: 421,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Note that, this model structure is a very basic one. \n",
        "    To achieve better performance, you should change the model structure and hyperparameters according to your needs and data. \n",
        "    So, optimize the structure of the model!\n",
        "\"\"\"\n",
        "\n",
        "def get_model():\n",
        "    activation_function = 'relu'\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), padding='same',\n",
        "                     activation=activation_function, input_shape=(img_rows, img_cols, num_of_channels)))\n",
        "    model.add(Conv2D(64, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(32, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(16, (3,3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(16, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    #model.add(Conv2D(64, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    #model.add(Conv2D(64, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    #model.add(Conv2D(128, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    #model.add(Dense(32, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    #model.add(Dense(16, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    model.add(Dense(number_of_class_labels, activation='softmax'))\n",
        "\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model = tf.keras.Sequential([\n",
        "#    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(120, 120, 3)),\n",
        "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#    tf.keras.layers.Dropout(0.25),\n",
        "#    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#    tf.keras.layers.Dropout(0.25),\n",
        "#    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#    tf.keras.layers.Dropout(0.25),\n",
        "#    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#    tf.keras.layers.Dropout(0.25),\n",
        "#    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#    tf.keras.layers.Dropout(0.25),\n",
        "#    #tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "#    #tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#    tf.keras.layers.Flatten(),\n",
        "#    #tf.keras.layers.Dropout(0.2),\n",
        "#    tf.keras.layers.Dense(128, activation='relu'),\n",
        "#    tf.keras.layers.Dense(18, activation='softmax')\n",
        "#])\n",
        "#\n",
        "#optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "#\n",
        "#model.compile(\n",
        "#    #optimizer='adam', \n",
        "#    optimizer=optimizer,\n",
        "#    loss='categorical_crossentropy',\n",
        "#    metrics=['accuracy'],\n",
        "#)\n",
        "#\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1i-6r91CUX5",
        "outputId": "285f1950-226b-4d2d-f6dd-467389dd1662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Found 1144 images belonging to 18 classes.\n",
            "Found 115 images belonging to 18 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-11 10:40:26.365166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-05-11 10:40:28.470710: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 117964800 exceeds 10% of free system memory.\n",
            "2023-05-11 10:40:29.046069: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 114065408 exceeds 10% of free system memory.\n",
            "2023-05-11 10:40:29.578978: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 29804544 exceeds 10% of free system memory.\n",
            "2023-05-11 10:40:29.587397: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 29804544 exceeds 10% of free system memory.\n",
            "2023-05-11 10:40:29.618933: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 29942784 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36/36 [==============================] - 57s 1s/step - loss: 2.8995 - accuracy: 0.0498\n",
            "Epoch 2/50\n",
            "36/36 [==============================] - 53s 1s/step - loss: 2.8913 - accuracy: 0.0516\n",
            "Epoch 3/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8907 - accuracy: 0.0472\n",
            "Epoch 4/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8914 - accuracy: 0.0481\n",
            "Epoch 5/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8925 - accuracy: 0.0664\n",
            "Epoch 6/50\n",
            "36/36 [==============================] - 50s 1s/step - loss: 2.8910 - accuracy: 0.0559\n",
            "Epoch 7/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8905 - accuracy: 0.0551\n",
            "Epoch 8/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8906 - accuracy: 0.0559\n",
            "Epoch 9/50\n",
            "36/36 [==============================] - 50s 1s/step - loss: 2.8911 - accuracy: 0.0638\n",
            "Epoch 10/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8917 - accuracy: 0.0533\n",
            "Epoch 11/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8913 - accuracy: 0.0577\n",
            "Epoch 12/50\n",
            "36/36 [==============================] - 50s 1s/step - loss: 2.8902 - accuracy: 0.0699\n",
            "Epoch 13/50\n",
            "36/36 [==============================] - 50s 1s/step - loss: 2.8904 - accuracy: 0.0577\n",
            "Epoch 14/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8906 - accuracy: 0.0472\n",
            "Epoch 15/50\n",
            "36/36 [==============================] - 50s 1s/step - loss: 2.8906 - accuracy: 0.0490\n",
            "Epoch 16/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8923 - accuracy: 0.0559\n",
            "Epoch 17/50\n",
            "36/36 [==============================] - 51s 1s/step - loss: 2.8905 - accuracy: 0.0568\n",
            "Epoch 18/50\n",
            "10/36 [=======>......................] - ETA: 36s - loss: 2.8908 - accuracy: 0.0353"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 51\u001b[0m\n\u001b[1;32m     43\u001b[0m validation_generator \u001b[39m=\u001b[39m validation_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[1;32m     44\u001b[0m     validation_path,\n\u001b[1;32m     45\u001b[0m     target_size\u001b[39m=\u001b[39m(img_rows, img_cols),\n\u001b[1;32m     46\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     47\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,  \u001b[39m# only data, no labels\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator,\n\u001b[1;32m     52\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m     54\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(validation_generator, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m y_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ===============Stratified K-Fold======================\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "fold_num = 0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    # First cut all images from validation to train (if any exists)\n",
        "    transfer_all_class_between_folders('validation', 'train'\n",
        "                                       , 1.0)\n",
        "    fold_num += 1\n",
        "    print(\"Results for fold\", fold_num)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for each_index in range(len(X_val)):\n",
        "        class_label = ''\n",
        "        for i in range(len(class_labels)):\n",
        "            if(Y_val[each_index] == i):\n",
        "                class_label = class_labels[i]\n",
        "        # Then, copy the validation images to the validation folder\n",
        "        shutil.move(os.path.join(dataset_folder_name, 'train', class_label, X_val[each_index]),\n",
        "                    os.path.join(dataset_folder_name, 'validation', class_label, X_val[each_index]))\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.20,\n",
        "        fill_mode=\"nearest\",\n",
        "        rotation_range=90,\n",
        "        height_shift_range=0.1,\n",
        "        width_shift_range=0.1,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True)\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Start ImageClassification Model\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)\n",
        "    \n",
        "    # fit model\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=epoch)\n",
        "\n",
        "    predictions = model.predict(validation_generator, verbose=1)\n",
        "    y_predictions = np.argmax(predictions, axis=1)\n",
        "    true_classes = validation_generator.classes\n",
        "    \n",
        "    # evaluate validation performance\n",
        "    print(\"***Performance on Validation data***\")\n",
        "    val_acc, val_prec, val_fScore = my_metrics(true_classes, y_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hG3Pzh9N61T",
        "outputId": "c92c5925-ba43-443f-8c89-9e63440e0a59"
      },
      "outputs": [],
      "source": [
        "print(\"==============TEST RESULTS============\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(img_rows, img_cols),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False \n",
        ")\n",
        "predictions = model.predict(test_generator, verbose=1) \n",
        "y_predictions = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "test_acc, test_prec, test_fScore = my_metrics(true_classes, y_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "clr = classification_report(true_classes, y_predictions,\n",
        "                            labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \n",
        "                            target_names=['a', 'ba','ca','da','ga','ja','ka','la','ma','na','nga','nya','pa','ra','sa','ta','wa','ya'])\n",
        "print(clr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#MODEL_FILENAME = root_path+\"/modelpengujian04_3x3_arsitektur2.h5\"\n",
        "#model.save(MODEL_FILENAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "24dc7b20f56b03d1f16e6cc38505b58c26a9c0d2aa82b50d0cbd183a5ef7f314"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
