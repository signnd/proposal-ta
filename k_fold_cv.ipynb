{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYRH4VUw8L9m"
      },
      "source": [
        "from: https://github.com/SadmanSakib93/Stratified-k-fold-cross-validation-Image-classification-keras/blob/master/stratified_K_fold_CV.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gdTY892I7gOi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:19:40.049512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-18 05:19:40.943472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current working directory:  /workspaces/proposal-ta\n"
          ]
        }
      ],
      "source": [
        "cwd = os.getcwd()\n",
        "print(\"current working directory: \",cwd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuDNA6xw8ngT",
        "outputId": "3949ad37-1348-45ab-d16d-eba8a5e4532b"
      },
      "outputs": [],
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls\n",
        "import sys\n",
        "# This is the path to where in google drive the code is stored!\n",
        "root_path = '/content/drive/My Drive/'\n",
        "sys.path.append(root_path)\n",
        "\"\"\"\n",
        "\n",
        "root_path = '/workspaces/proposal-ta/images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E8wVsnsN8_ZB"
      },
      "outputs": [],
      "source": [
        "### UBAH NAMA FILE MODEL SESUAI PENGUJIAN DI SINI\n",
        "dataset_folder_name = os.path.join(root_path, '')\n",
        "source_files = []\n",
        "class_labels = ['a', 'ba', 'ca', 'da', 'ga', \n",
        "                'ja', 'ka','la','ma', 'na', \n",
        "                'nga', 'nya','pa', 'ra', 'sa', \n",
        "                'ta', 'wa', 'ya']\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "img_rows, img_cols = 120, 120 # input image dimensions\n",
        "train_path = os.path.join(dataset_folder_name, 'train')\n",
        "validation_path = os.path.join(dataset_folder_name, 'validation')\n",
        "test_path = os.path.join(dataset_folder_name, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# augmentasi data\n",
        "# bisa jadi sebelum atau setelah split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hQTAVyDu92QO"
      },
      "outputs": [],
      "source": [
        "def transfer_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Based on the split ratio this function moves some portion of the source folder to destination folder!\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest location\n",
        "\n",
        "    \"\"\"\n",
        "    global source_files\n",
        "    source_files = os.listdir(source)\n",
        "    if(len(source_files) != 0):\n",
        "        transfer_file_numbers = int(len(source_files)*split_rate)\n",
        "        transfer_index = random.sample(\n",
        "            range(0, len(source_files)), transfer_file_numbers)\n",
        "        for each_index in transfer_index:\n",
        "            shutil.move(os.path.join(source, str(source_files[each_index])), os.path.join(\n",
        "                dest, str(source_files[each_index])))\n",
        "\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "\n",
        "\n",
        "def transfer_all_class_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Transfer the files from source to dest for all the classes. This function calls the 'transfer_between_folders' to actually perform the transfer.\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest location\n",
        "\n",
        "    \"\"\"\n",
        "    for label in class_labels:\n",
        "        transfer_between_folders(os.path.join(dataset_folder_name, source, label),\n",
        "                                 os.path.join(\n",
        "                                     dataset_folder_name, dest, label),\n",
        "                                 split_rate)\n",
        "\n",
        "\n",
        "def my_metrics(y_true, y_pred):\n",
        "    \"\"\" Calculate accuracy, precision, and f1 score of the model's prediction with respect to true labels.\n",
        "\n",
        "        Args:\n",
        "            y_true: list/array\n",
        "                All true class labels\n",
        "            y_pred: list/array\n",
        "                All predicted class labels\n",
        "\n",
        "        Returns:\n",
        "            accuracy: float\n",
        "                Accuracy measure of the model\n",
        "            precision: float\n",
        "                Precision measure of the model\n",
        "            f1_Score: float\n",
        "                F1-score measure of the model\n",
        "\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    f1_Score = f1_score(y_true, y_pred, average='weighted')\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1_Score))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fTSdYcqD-IW5"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('test','train', 1.0)\n",
        "#transfer_all_class_between_folders('validation','train', 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9TdfECoaBoja"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('train', 'test', 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HAeKZkmDBuCx"
      },
      "outputs": [],
      "source": [
        "def prepare_name_with_labels(folder_name, dataset_type='train'):\n",
        "    \"\"\" Prepare the file names (X) and the class labels (Y) from folder location of images.\n",
        "\n",
        "        Args:\n",
        "            folder_name: str\n",
        "                Source folder's path\n",
        "\n",
        "    \"\"\"\n",
        "    source_files = os.listdir(os.path.join(dataset_folder_name, dataset_type, folder_name))\n",
        "    y_label = 0\n",
        "    for i in range(len(class_labels)):\n",
        "        if(folder_name == class_labels[i]):\n",
        "            y_label = i\n",
        "    for val in source_files:\n",
        "        X.append(val)\n",
        "        Y.append(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZXi4N1qSBy8A"
      },
      "outputs": [],
      "source": [
        "# Organize file names and class labels in X and Y variables\n",
        "for i in range(len(class_labels)):\n",
        "    prepare_name_with_labels(class_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h3aTsDa5B155"
      },
      "outputs": [],
      "source": [
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8DKyU0MOB3Tj"
      },
      "outputs": [],
      "source": [
        "# arsitektur\n",
        "batch_size = 32\n",
        "epoch = 15\n",
        "num_of_channels = 3\n",
        "number_of_class_labels = len(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1ljNTaGaCIzc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 120, 120, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 118, 118, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 59, 59, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 59, 59, 32)        18464     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 57, 57, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 26, 26, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2704)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               346240    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                2322      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 421,938\n",
            "Trainable params: 421,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Note that, this model structure is a very basic one. \n",
        "    To achieve better performance, you should change the model structure and hyperparameters according to your needs and data. \n",
        "    So, optimize the structure of the model!\n",
        "\"\"\"\n",
        "\n",
        "def get_model():\n",
        "    activation_function = 'relu'\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), padding='same',\n",
        "                     activation=activation_function, input_shape=(img_rows, img_cols, num_of_channels)))\n",
        "    model.add(Conv2D(64, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(32, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(16, (3,3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(16, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    #model.add(Conv2D(64, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    #model.add(Conv2D(64, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    #model.add(Conv2D(128, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    #model.add(Dense(32, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    #model.add(Dense(16, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    model.add(Dense(number_of_class_labels, activation='softmax'))\n",
        "\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(120, 120, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    #tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "model.compile(\n",
        "    #optimizer='adam', \n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.summary()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1i-6r91CUX5",
        "outputId": "285f1950-226b-4d2d-f6dd-467389dd1662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "Results for fold 1\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:20:22.101808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 45s 1s/step - loss: 2.8933 - accuracy: 0.0531\n",
            "Epoch 2/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 2.4210 - accuracy: 0.2789\n",
            "Epoch 3/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 1.0405 - accuracy: 0.7017\n",
            "Epoch 4/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.6061 - accuracy: 0.8274\n",
            "Epoch 5/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.4894 - accuracy: 0.8427\n",
            "Epoch 6/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.3698 - accuracy: 0.8958\n",
            "Epoch 7/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.3123 - accuracy: 0.8989\n",
            "Epoch 8/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.2443 - accuracy: 0.9213\n",
            "Epoch 9/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.1711 - accuracy: 0.9459\n",
            "Epoch 10/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.1257 - accuracy: 0.9602\n",
            "Epoch 11/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.1286 - accuracy: 0.9581\n",
            "Epoch 12/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.1332 - accuracy: 0.9622\n",
            "Epoch 13/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0913 - accuracy: 0.9683\n",
            "Epoch 14/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0871 - accuracy: 0.9673\n",
            "Epoch 15/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0793 - accuracy: 0.9806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:31:05.211426: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 237ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.8326530612244898\n",
            "Precision : 0.8507907690127947\n",
            "f1Score : 0.8345101154725271\n",
            "[[12  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0]\n",
            " [ 0 10  0  0  3  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0 12  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  1  0  0  0  2  0  0  0  0]\n",
            " [ 0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 11  0  0  0  0  0  1  0  0  0  0  2  0]\n",
            " [ 0  0  0  0  1  0 12  0  0  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 10  0  0  0  0  1  0  2  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0 12  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0 11  0  0  2  0  0  0  0]\n",
            " [ 0  4  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  1  0  0  0  0  0  1 11  0  0  0  0]\n",
            " [ 0  0  2  0  0  0  0  0  1  0  0  0  1  0  9  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0]\n",
            " [ 0  0  1  1  0  0  0  0  0  0  0  0  3  0  0  0  9  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12]]\n",
            "Results for fold 2\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:31:07.469766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 42s 1s/step - loss: 0.2250 - accuracy: 0.9418\n",
            "Epoch 2/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.1679 - accuracy: 0.9520\n",
            "Epoch 3/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.1043 - accuracy: 0.9714\n",
            "Epoch 4/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0898 - accuracy: 0.9765\n",
            "Epoch 5/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.1112 - accuracy: 0.9724\n",
            "Epoch 6/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0687 - accuracy: 0.9796\n",
            "Epoch 7/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0805 - accuracy: 0.9806\n",
            "Epoch 8/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0609 - accuracy: 0.9898\n",
            "Epoch 9/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0559 - accuracy: 0.9796\n",
            "Epoch 10/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0201 - accuracy: 0.9939\n",
            "Epoch 11/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0626 - accuracy: 0.9837\n",
            "Epoch 12/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0663 - accuracy: 0.9816\n",
            "Epoch 13/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0390 - accuracy: 0.9857\n",
            "Epoch 14/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0106 - accuracy: 0.9980\n",
            "Epoch 15/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0514 - accuracy: 0.9847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:42:21.777172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 242ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9714285714285714\n",
            "Precision : 0.9736443148688047\n",
            "f1Score : 0.9717036441286969\n",
            "[[14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 12  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 12  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1 13  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 13  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 12  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n",
            "Results for fold 3\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:42:23.948712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 42s 1s/step - loss: 0.0604 - accuracy: 0.9877\n",
            "Epoch 2/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0420 - accuracy: 0.9847\n",
            "Epoch 3/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0314 - accuracy: 0.9908\n",
            "Epoch 4/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0467 - accuracy: 0.9857\n",
            "Epoch 5/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0303 - accuracy: 0.9898\n",
            "Epoch 6/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0428 - accuracy: 0.9877\n",
            "Epoch 7/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0260 - accuracy: 0.9888\n",
            "Epoch 8/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0266 - accuracy: 0.9908\n",
            "Epoch 9/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0113 - accuracy: 0.9949\n",
            "Epoch 10/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0163 - accuracy: 0.9939\n",
            "Epoch 11/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0208 - accuracy: 0.9928\n",
            "Epoch 12/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0183 - accuracy: 0.9969\n",
            "Epoch 13/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0211 - accuracy: 0.9939\n",
            "Epoch 14/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0070 - accuracy: 0.9980\n",
            "Epoch 15/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0026 - accuracy: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:53:36.198115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 240ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9918367346938776\n",
            "Precision : 0.9923809523809524\n",
            "f1Score : 0.9918202622044987\n",
            "[[14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 12  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n",
            "Results for fold 4\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 05:53:38.323995: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 42s 1s/step - loss: 0.0463 - accuracy: 0.9908\n",
            "Epoch 2/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0252 - accuracy: 0.9898\n",
            "Epoch 3/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0274 - accuracy: 0.9908\n",
            "Epoch 4/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0183 - accuracy: 0.9949\n",
            "Epoch 5/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0094 - accuracy: 0.9959\n",
            "Epoch 6/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0276 - accuracy: 0.9928\n",
            "Epoch 7/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0107 - accuracy: 0.9969\n",
            "Epoch 8/15\n",
            "31/31 [==============================] - 41s 1s/step - loss: 0.0254 - accuracy: 0.9980\n",
            "Epoch 9/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0188 - accuracy: 0.9959\n",
            "Epoch 10/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0109 - accuracy: 0.9980\n",
            "Epoch 11/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0126 - accuracy: 0.9949\n",
            "Epoch 12/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0310 - accuracy: 0.9949\n",
            "Epoch 13/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0204 - accuracy: 0.9959\n",
            "Epoch 14/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0112 - accuracy: 0.9980\n",
            "Epoch 15/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0095 - accuracy: 0.9959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 06:04:52.422388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 255ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9959183673469387\n",
            "Precision : 0.9962099125364431\n",
            "f1Score : 0.9959183673469387\n",
            "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 13  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n",
            "Results for fold 5\n",
            "Found 980 images belonging to 18 classes.\n",
            "Found 244 images belonging to 18 classes.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 06:04:54.725404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 43s 1s/step - loss: 0.0167 - accuracy: 0.9939\n",
            "Epoch 2/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0174 - accuracy: 0.9949\n",
            "Epoch 3/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0159 - accuracy: 0.9949\n",
            "Epoch 4/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0156 - accuracy: 0.9949\n",
            "Epoch 5/15\n",
            " 2/31 [>.............................] - ETA: 42s - loss: 0.0048 - accuracy: 1.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Bad pipe message: %s [b'\\xbd\\xf5\\xae|\\x02\\x19\\xa1\\x87\\x81\\x94\\x8c<\\xefeYcb. q\\xa3\\x0bOL\\xeb\\xb7\\xdfD\\xfb\"H\\x01\\xd1\\xe1\\x8a@U\\xaa\\xeb\\xb7h:2\\xd2\\x04\\xf7\\xd5\\xa4\\x7f\\xa0G\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00', b'\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01']\n",
            "Bad pipe message: %s [b'\\\\\\x8f\\x1fN2\\xf8G]\\x0e\\xb0\\xb6\\x91_cm4+\\xad \\x0e\\x9ew\\xad\\x0c\\xdb']\n",
            "Bad pipe message: %s [b'Q\\x1e\\xd3\\x02\\xff\\xc8\\xa1>F\\x9f\\xa4\\x81l\\x12\\xff?\\xf8\\xcaYS\\x8a\\xce^/\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00', b'\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07']\n",
            "Bad pipe message: %s [b'\\x08\\t\\x08\\n\\x08\\x0b\\x08']\n",
            "Bad pipe message: %s [b'\\x05\\x08\\x06']\n",
            "Bad pipe message: %s [b'\\x05\\x01\\x06', b'']\n",
            "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00  \\xc4I$\\xdaW\\xf5su\\xcf\\xae\\xcc\\x02\\xd9Gi\\xc6TN\\x00\\x8a\\xde']\n",
            "Bad pipe message: %s [b'c\\x05Y\\xd2(\\xa1\\xe1\"O\\x1e}\\x84\\xc8\\xa8\\x9d\\xd8\\xd4M\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0\\'\\x00g']\n",
            "Bad pipe message: %s [b'\\x8bq\\x00fh\\xa6q\\xd8\\x04)\\xfeJ\\x9d\\xb4k\\xfa\\xc4\\x10\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0', b'g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00']\n",
            "Bad pipe message: %s [b'\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127']\n",
            "Bad pipe message: %s [b'.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00']\n",
            "Bad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03\\x03\\x01\\x02\\x01\\x03\\x02\\x02\\x02\\x04\\x02\\x05\\x02\\x06\\x02']\n",
            "Bad pipe message: %s [b'J\\xe1\\x02\\xd8\\x83e\\x07kh\\x96%bZd\\x1b\\x8dYL\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00', b'\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00']\n",
            "Bad pipe message: %s [b'\\x91\\xf1\\x00\\x8b\\x9f\\x9c\\x16\\x86\\xf6L\\x8c\\xaemq&\\xbc\\x81#\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0']\n",
            "Bad pipe message: %s [b'\\x0c\\xc0\\x02\\x00\\x05\\x00']\n",
            "Bad pipe message: %s [b'\\xff\\x02\\x01']\n",
            "Bad pipe message: %s [b'-\\x1asl\\xaa&JF2\\xff\\xee\\x02Z\\xa1m\\x10\\x0e\\x84\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99']\n",
            "Bad pipe message: %s [b'\\xe2t\\x03\\xa7\\xef\\xadg\\xc2kv\\xc2=\\xe5\\xc2\\xf5z-\\x9f\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0']\n",
            "Bad pipe message: %s [b\"\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0\"]\n",
            "Bad pipe message: %s [b'\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0']\n",
            "Bad pipe message: %s [b'\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02']\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b\"\\x9c\\xf8\\x06\\xfd\\xb6\\xe5\\xd1\\x02\\x94R\\x9eQN\\xdd1i9M\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0\"]\n",
            "Bad pipe message: %s [b'\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00']\n",
            "Bad pipe message: %s [b'\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 44s 1s/step - loss: 0.0152 - accuracy: 0.9949\n",
            "Epoch 6/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0304 - accuracy: 0.9898\n",
            "Epoch 7/15\n",
            "31/31 [==============================] - 43s 1s/step - loss: 0.0284 - accuracy: 0.9929\n",
            "Epoch 8/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0176 - accuracy: 0.9939\n",
            "Epoch 9/15\n",
            "31/31 [==============================] - 41s 1s/step - loss: 0.0091 - accuracy: 0.9969\n",
            "Epoch 10/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0137 - accuracy: 0.9949\n",
            "Epoch 11/15\n",
            "31/31 [==============================] - 41s 1s/step - loss: 0.1272 - accuracy: 0.9765\n",
            "Epoch 12/15\n",
            "31/31 [==============================] - 41s 1s/step - loss: 0.0245 - accuracy: 0.9949\n",
            "Epoch 13/15\n",
            "31/31 [==============================] - 41s 1s/step - loss: 0.0109 - accuracy: 0.9969\n",
            "Epoch 14/15\n",
            "31/31 [==============================] - 41s 1s/step - loss: 0.0050 - accuracy: 0.9980\n",
            "Epoch 15/15\n",
            "31/31 [==============================] - 42s 1s/step - loss: 0.0031 - accuracy: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 06:15:25.599012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 227ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9959016393442623\n",
            "Precision : 0.9961748633879781\n",
            "f1Score : 0.9958903335217638\n",
            "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "# ===============Stratified K-Fold======================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "fold_num = 0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    # First cut all images from validation to train (if any exists)\n",
        "    transfer_all_class_between_folders('validation', 'train'\n",
        "                                       , 1.0)\n",
        "    fold_num += 1\n",
        "    print(\"Results for fold\", fold_num)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for each_index in range(len(X_val)):\n",
        "        class_label = ''\n",
        "        for i in range(len(class_labels)):\n",
        "            if(Y_val[each_index] == i):\n",
        "                class_label = class_labels[i]\n",
        "        # Then, copy the validation images to the validation folder\n",
        "        shutil.move(os.path.join(dataset_folder_name, 'train', class_label, X_val[each_index]),\n",
        "                    os.path.join(dataset_folder_name, 'validation', class_label, X_val[each_index]))\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.20,\n",
        "        fill_mode=\"nearest\")\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Start ImageClassification Model\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)\n",
        "    \n",
        "    # fit model\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=epoch)\n",
        "\n",
        "    predictions = model.predict(validation_generator, verbose=1)\n",
        "    y_predictions = np.argmax(predictions, axis=1)\n",
        "    true_classes = validation_generator.classes\n",
        "    \n",
        "    # evaluate validation performance\n",
        "    print(\"***Performance on Validation data***\")\n",
        "    val_acc, val_prec, val_fScore = my_metrics(true_classes, y_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hG3Pzh9N61T",
        "outputId": "c92c5925-ba43-443f-8c89-9e63440e0a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============TEST RESULTS============\n",
            "Found 305 images belonging to 18 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 06:17:23.660943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 3s 250ms/step\n",
            "Accuracy  : 0.9278688524590164\n",
            "Precision : 0.9320544530725722\n",
            "f1Score : 0.9273168366144624\n",
            "[[16  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
            " [ 0 13  0  0  0  2  0  0  0  0  1  1  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  1  0  0  0  0  0  0  0  1  2  0  1  0]\n",
            " [ 0  0  0 16  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0 15  0  1  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  1  0  0 16  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  0 16  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0 16  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 16  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17]]\n"
          ]
        }
      ],
      "source": [
        "print(\"==============TEST RESULTS============\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(img_rows, img_cols),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False \n",
        ")\n",
        "predictions = model.predict(test_generator, verbose=1) \n",
        "y_predictions = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "test_acc, test_prec, test_fScore = my_metrics(true_classes, y_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           a       1.00      0.94      0.97        17\n",
            "          ba       0.87      0.76      0.81        17\n",
            "          ca       1.00      0.71      0.83        17\n",
            "          da       1.00      0.94      0.97        17\n",
            "          ga       1.00      1.00      1.00        16\n",
            "          ja       0.79      0.88      0.83        17\n",
            "          ka       0.94      1.00      0.97        17\n",
            "          la       0.94      0.94      0.94        17\n",
            "          ma       0.94      0.94      0.94        17\n",
            "          na       1.00      0.94      0.97        17\n",
            "         nga       0.94      0.94      0.94        17\n",
            "         nya       0.94      0.94      0.94        17\n",
            "          pa       0.94      0.94      0.94        17\n",
            "          ra       0.85      1.00      0.92        17\n",
            "          sa       0.83      0.88      0.86        17\n",
            "          ta       1.00      1.00      1.00        17\n",
            "          wa       0.94      0.94      0.94        17\n",
            "          ya       0.85      1.00      0.92        17\n",
            "\n",
            "    accuracy                           0.93       305\n",
            "   macro avg       0.93      0.93      0.93       305\n",
            "weighted avg       0.93      0.93      0.93       305\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "clr = classification_report(true_classes, y_predictions,\n",
        "                            labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \n",
        "                            target_names=['a', 'ba','ca','da','ga','ja','ka','la','ma','na','nga','nya','pa','ra','sa','ta','wa','ya'])\n",
        "print(clr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_FILENAME = root_path+\"/modelpengujian20_3x3_arsitektur2.h5\"\n",
        "model.save(MODEL_FILENAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "24dc7b20f56b03d1f16e6cc38505b58c26a9c0d2aa82b50d0cbd183a5ef7f314"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
