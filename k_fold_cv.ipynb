{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYRH4VUw8L9m"
      },
      "source": [
        "from: https://github.com/SadmanSakib93/Stratified-k-fold-cross-validation-Image-classification-keras/blob/master/stratified_K_fold_CV.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gdTY892I7gOi"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, f1_score, precision_score, confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m StratifiedKFold\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuDNA6xw8ngT",
        "outputId": "3949ad37-1348-45ab-d16d-eba8a5e4532b"
      },
      "outputs": [],
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls\n",
        "import sys\n",
        "# This is the path to where in google drive the code is stored!\n",
        "root_path = '/content/drive/My Drive/'\n",
        "sys.path.append(root_path)\n",
        "\"\"\"\n",
        "\n",
        "root_path = 'images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E8wVsnsN8_ZB"
      },
      "outputs": [],
      "source": [
        "### UBAH NAMA FILE MODEL SESUAI PENGUJIAN DI SINI\n",
        "dataset_folder_name = os.path.join(root_path, 'all')\n",
        "source_files = []\n",
        "class_labels = ['a', 'ba', 'ca', 'da', 'ga', \n",
        "                'ja', 'ka','la','ma', 'na', \n",
        "                'nga', 'nya','pa', 'ra', 'sa', \n",
        "                'ta', 'wa', 'ya']\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "img_rows, img_cols = 120, 120 # input image dimensions\n",
        "train_path = os.path.join(dataset_folder_name, 'train')\n",
        "validation_path = os.path.join(dataset_folder_name, 'validation')\n",
        "test_path = os.path.join(dataset_folder_name, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# augmentasi data\n",
        "# bisa jadi sebelum atau setelah split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hQTAVyDu92QO"
      },
      "outputs": [],
      "source": [
        "def transfer_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Based on the split ratio this function moves some portion of the source folder to destination folder!\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest location\n",
        "\n",
        "    \"\"\"\n",
        "    global source_files\n",
        "    source_files = os.listdir(source)\n",
        "    if(len(source_files) != 0):\n",
        "        transfer_file_numbers = int(len(source_files)*split_rate)\n",
        "        transfer_index = random.sample(\n",
        "            range(0, len(source_files)), transfer_file_numbers)\n",
        "        for each_index in transfer_index:\n",
        "            shutil.move(os.path.join(source, str(source_files[each_index])), os.path.join(\n",
        "                dest, str(source_files[each_index])))\n",
        "\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "\n",
        "\n",
        "def transfer_all_class_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Transfer the files from source to dest for all the classes. This function calls the 'transfer_between_folders' to actually perform the transfer.\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest location\n",
        "\n",
        "    \"\"\"\n",
        "    for label in class_labels:\n",
        "        transfer_between_folders(os.path.join(dataset_folder_name, source, label),\n",
        "                                 os.path.join(\n",
        "                                     dataset_folder_name, dest, label),\n",
        "                                 split_rate)\n",
        "\n",
        "\n",
        "def my_metrics(y_true, y_pred):\n",
        "    \"\"\" Calculate accuracy, precision, and f1 score of the model's prediction with respect to true labels.\n",
        "\n",
        "        Args:\n",
        "            y_true: list/array\n",
        "                All true class labels\n",
        "            y_pred: list/array\n",
        "                All predicted class labels\n",
        "\n",
        "        Returns:\n",
        "            accuracy: float\n",
        "                Accuracy measure of the model\n",
        "            precision: float\n",
        "                Precision measure of the model\n",
        "            f1_Score: float\n",
        "                F1-score measure of the model\n",
        "\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    f1_Score = f1_score(y_true, y_pred, average='weighted')\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1_Score))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fTSdYcqD-IW5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n"
          ]
        }
      ],
      "source": [
        "transfer_all_class_between_folders('test','train', 1.0)\n",
        "transfer_all_class_between_folders('validation','train', 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9TdfECoaBoja"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('train', 'test', 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HAeKZkmDBuCx"
      },
      "outputs": [],
      "source": [
        "def prepare_name_with_labels(folder_name, dataset_type='train'):\n",
        "    \"\"\" Prepare the file names (X) and the class labels (Y) from folder location of images.\n",
        "\n",
        "        Args:\n",
        "            folder_name: str\n",
        "                Source folder's path\n",
        "\n",
        "    \"\"\"\n",
        "    source_files = os.listdir(os.path.join(dataset_folder_name, dataset_type, folder_name))\n",
        "    y_label = 0\n",
        "    for i in range(len(class_labels)):\n",
        "        if(folder_name == class_labels[i]):\n",
        "            y_label = i\n",
        "    for val in source_files:\n",
        "        X.append(val)\n",
        "        Y.append(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZXi4N1qSBy8A"
      },
      "outputs": [],
      "source": [
        "# Organize file names and class labels in X and Y variables\n",
        "for i in range(len(class_labels)):\n",
        "    prepare_name_with_labels(class_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h3aTsDa5B155"
      },
      "outputs": [],
      "source": [
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8DKyU0MOB3Tj"
      },
      "outputs": [],
      "source": [
        "# arsitektur\n",
        "batch_size = 128\n",
        "epoch = 15\n",
        "num_of_channels = 3\n",
        "number_of_class_labels = len(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1ljNTaGaCIzc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 120, 120, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 118, 118, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 59, 59, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 59, 59, 32)        18464     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 57, 57, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 16)        4624      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 26, 26, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2704)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               346240    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                2322      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 421,938\n",
            "Trainable params: 421,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Note that, this model structure is a very basic one. \n",
        "    To achieve better performance, you should change the model structure and hyperparameters according to your needs and data. \n",
        "    So, optimize the structure of the model!\n",
        "\"\"\"\n",
        "\n",
        "def get_model():\n",
        "    activation_function = 'relu'\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), padding='same',\n",
        "                     activation=activation_function, input_shape=(img_rows, img_cols, num_of_channels)))\n",
        "    model.add(Conv2D(64, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(32, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(16, (3,3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(16, (3,3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    #model.add(Conv2D(64, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    #model.add(Conv2D(64, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    #model.add(Conv2D(128, (3,3), padding='same',\n",
        "    #                 activation=activation_function))\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    #model.add(Dense(32, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    #model.add(Dense(16, activation=activation_function))\n",
        "    #model.add(Dropout(0.1))\n",
        "    model.add(Dense(number_of_class_labels, activation='softmax'))\n",
        "\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"model = tf.keras.Sequential([\\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(120, 120, 3)),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    #tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\\n    #tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Flatten(),\\n    #tf.keras.layers.Dropout(0.2),\\n    tf.keras.layers.Dense(128, activation='relu'),\\n    tf.keras.layers.Dense(18, activation='softmax')\\n])\\n\\noptimizer=tf.keras.optimizers.Adam(learning_rate=0.005)\\n\\nmodel.compile(\\n    #optimizer='adam', \\n    optimizer=optimizer,\\n    loss='categorical_crossentropy',\\n    metrics=['accuracy'],\\n)\\n\\nmodel.summary()\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(120, 120, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    #tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "model.compile(\n",
        "    #optimizer='adam', \n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.summary()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1i-6r91CUX5",
        "outputId": "285f1950-226b-4d2d-f6dd-467389dd1662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "Results for fold 1\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n",
            "8/8 [==============================] - 165s 17s/step - loss: 2.8911 - accuracy: 0.0562\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 124s 15s/step - loss: 2.8619 - accuracy: 0.1685\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 135s 17s/step - loss: 2.5925 - accuracy: 0.3075\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 119s 15s/step - loss: 1.6446 - accuracy: 0.5649\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 145s 18s/step - loss: 1.1260 - accuracy: 0.6813\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 196s 26s/step - loss: 0.8319 - accuracy: 0.7487\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 134s 16s/step - loss: 0.6665 - accuracy: 0.7865\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.5613 - accuracy: 0.8437\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 121s 15s/step - loss: 0.4918 - accuracy: 0.8652\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 120s 15s/step - loss: 0.4405 - accuracy: 0.8703\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 128s 16s/step - loss: 0.3516 - accuracy: 0.9019\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 121s 15s/step - loss: 0.3082 - accuracy: 0.9111\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 120s 15s/step - loss: 0.2692 - accuracy: 0.9142\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 121s 15s/step - loss: 0.2066 - accuracy: 0.9397\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 120s 15s/step - loss: 0.1835 - accuracy: 0.9377\n",
            "2/2 [==============================] - 10s 4s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.8612244897959184\n",
            "Precision : 0.8771690214547357\n",
            "f1Score : 0.862805360693289\n",
            "[[14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 11  0  0  1  0  0  1  0  0  0  0  0  0  0  1  0  0]\n",
            " [ 0  0 11  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  2  0 12  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0 11  0  0  1  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 11  1  0  0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0  1  0  0  0  0 12  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  2  0  0  1  0  0  8  1  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1 13  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0  0  0  0  0  0  0 11  0  1  0  0  0]\n",
            " [ 0  0  0  1  0  0  0  0  0  0  0  0  0 13  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0]\n",
            " [ 1  0  0  1  0  0  0  0  0  0  0  0  0  1  0 11  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0 12  0]\n",
            " [ 0  0  0  1  0  1  0  0  0  0  0  0  0  0  1  0  0 10]]\n",
            "Results for fold 2\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.3341 - accuracy: 0.9152\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 130s 16s/step - loss: 0.2620 - accuracy: 0.9326\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.1972 - accuracy: 0.9448\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.1670 - accuracy: 0.9510\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 126s 16s/step - loss: 0.1336 - accuracy: 0.9581\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.1430 - accuracy: 0.9520\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 118s 14s/step - loss: 0.1181 - accuracy: 0.9663\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.0821 - accuracy: 0.9755\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 118s 14s/step - loss: 0.0905 - accuracy: 0.9806\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.0629 - accuracy: 0.9796\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 115s 14s/step - loss: 0.0472 - accuracy: 0.9867\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0463 - accuracy: 0.9847\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 120s 15s/step - loss: 0.0523 - accuracy: 0.9857\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.0444 - accuracy: 0.9867\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0603 - accuracy: 0.9785\n",
            "2/2 [==============================] - 8s 4s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9224489795918367\n",
            "Precision : 0.9299477433330975\n",
            "f1Score : 0.9225848255010817\n",
            "[[14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 11  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
            " [ 0  0  0  0 12  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 12  0  0  0  0  2  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0 13  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0 13  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  0  0 13  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  1 10  0]\n",
            " [ 0  0  0  2  0  0  0  0  0  0  0  0  1  0  0  0  0 11]]\n",
            "Results for fold 3\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n",
            "8/8 [==============================] - 120s 15s/step - loss: 0.1393 - accuracy: 0.9663\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.1244 - accuracy: 0.9612\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 121s 16s/step - loss: 0.0915 - accuracy: 0.9724\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.0677 - accuracy: 0.9775\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 135s 17s/step - loss: 0.0578 - accuracy: 0.9806\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 118s 14s/step - loss: 0.0604 - accuracy: 0.9826\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 116s 14s/step - loss: 0.0570 - accuracy: 0.9867\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.0397 - accuracy: 0.9867\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.0622 - accuracy: 0.9837\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 116s 15s/step - loss: 0.0444 - accuracy: 0.9877\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0384 - accuracy: 0.9908\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0261 - accuracy: 0.9939\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0316 - accuracy: 0.9898\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0207 - accuracy: 0.9949\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 116s 14s/step - loss: 0.0265 - accuracy: 0.9918\n",
            "2/2 [==============================] - 9s 4s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9959183673469387\n",
            "Precision : 0.9962099125364432\n",
            "f1Score : 0.9959183673469387\n",
            "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n",
            "Results for fold 4\n",
            "Found 979 images belonging to 18 classes.\n",
            "Found 245 images belonging to 18 classes.\n",
            "Epoch 1/15\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.0346 - accuracy: 0.9857\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 118s 15s/step - loss: 0.0385 - accuracy: 0.9888\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 120s 15s/step - loss: 0.0318 - accuracy: 0.9918\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0224 - accuracy: 0.9918\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 124s 15s/step - loss: 0.0139 - accuracy: 0.9969\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 113s 15s/step - loss: 0.0155 - accuracy: 0.9990\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0155 - accuracy: 0.9959\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0103 - accuracy: 0.9959\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0121 - accuracy: 0.9969\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 118s 14s/step - loss: 0.0231 - accuracy: 0.9908\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 124s 15s/step - loss: 0.0245 - accuracy: 0.9939\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 118s 14s/step - loss: 0.0218 - accuracy: 0.9918\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 123s 15s/step - loss: 0.0411 - accuracy: 0.9826\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 140s 18s/step - loss: 0.0303 - accuracy: 0.9908\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 139s 17s/step - loss: 0.0204 - accuracy: 0.9949\n",
            "2/2 [==============================] - 9s 4s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9877551020408163\n",
            "Precision : 0.9885714285714285\n",
            "f1Score : 0.9877394636015326\n",
            "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 13  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 13  0  0  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n",
            "Results for fold 5\n",
            "Found 980 images belonging to 18 classes.\n",
            "Found 244 images belonging to 18 classes.\n",
            "Epoch 1/15\n",
            "8/8 [==============================] - 134s 16s/step - loss: 0.0358 - accuracy: 0.9847\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 124s 15s/step - loss: 0.0229 - accuracy: 0.9908\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 128s 16s/step - loss: 0.0327 - accuracy: 0.9908\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 125s 15s/step - loss: 0.0181 - accuracy: 0.9929\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 118s 14s/step - loss: 0.0127 - accuracy: 0.9969\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 131s 16s/step - loss: 0.0069 - accuracy: 0.9980\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 130s 16s/step - loss: 0.0076 - accuracy: 0.9980\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.0051 - accuracy: 0.9980\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 114s 14s/step - loss: 0.0088 - accuracy: 0.9969\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 133s 16s/step - loss: 0.0072 - accuracy: 0.9980\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 125s 15s/step - loss: 0.0242 - accuracy: 0.9929\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 108s 13s/step - loss: 0.0189 - accuracy: 0.9939\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 123s 15s/step - loss: 0.0117 - accuracy: 0.9959\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 119s 15s/step - loss: 0.0132 - accuracy: 0.9959\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 117s 14s/step - loss: 0.0165 - accuracy: 0.9959\n",
            "2/2 [==============================] - 12s 6s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9795081967213115\n",
            "Precision : 0.9813914910226386\n",
            "f1Score : 0.9792711891567176\n",
            "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 12  0  0  0  0  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  1  0  0  0  0 11  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "# ===============Stratified K-Fold======================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "fold_num = 0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    # First cut all images from validation to train (if any exists)\n",
        "    transfer_all_class_between_folders('validation', 'train'\n",
        "                                       , 1.0)\n",
        "    fold_num += 1\n",
        "    print(\"Results for fold\", fold_num)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for each_index in range(len(X_val)):\n",
        "        class_label = ''\n",
        "        for i in range(len(class_labels)):\n",
        "            if(Y_val[each_index] == i):\n",
        "                class_label = class_labels[i]\n",
        "        # Then, copy the validation images to the validation folder\n",
        "        shutil.move(os.path.join(dataset_folder_name, 'train', class_label, X_val[each_index]),\n",
        "                    os.path.join(dataset_folder_name, 'validation', class_label, X_val[each_index]))\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.20,\n",
        "        fill_mode=\"nearest\")\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Start ImageClassification Model\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)\n",
        "    \n",
        "    # fit model\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=epoch)\n",
        "\n",
        "    predictions = model.predict(validation_generator, verbose=1)\n",
        "    y_predictions = np.argmax(predictions, axis=1)\n",
        "    true_classes = validation_generator.classes\n",
        "    \n",
        "    # evaluate validation performance\n",
        "    print(\"***Performance on Validation data***\")\n",
        "    val_acc, val_prec, val_fScore = my_metrics(true_classes, y_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hG3Pzh9N61T",
        "outputId": "c92c5925-ba43-443f-8c89-9e63440e0a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============TEST RESULTS============\n",
            "Found 305 images belonging to 18 classes.\n",
            "3/3 [==============================] - 13s 3s/step\n",
            "Accuracy  : 0.9016393442622951\n",
            "Precision : 0.9128592730936391\n",
            "f1Score : 0.9016419528649982\n",
            "[[13  0  0  0  0  0  1  0  0  0  0  1  2  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  1  0  0  0  0  0  2  0  0  0  0  0  0]\n",
            " [ 0  0 16  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 14  0  0  0  0  0  2  0  0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 15  0  0  0  0  2  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  0 16  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  2  1  0  0  0  0 14  0  0  0  0  0  0  0]\n",
            " [ 0  2  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  0 16  0  0  0  0]\n",
            " [ 0  0  2  0  0  0  0  0  1  0  0  0  0  0 13  1  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  1  0 14  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0 15  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17]]\n"
          ]
        }
      ],
      "source": [
        "print(\"==============TEST RESULTS============\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(img_rows, img_cols),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False \n",
        ")\n",
        "predictions = model.predict(test_generator, verbose=1) \n",
        "y_predictions = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "test_acc, test_prec, test_fScore = my_metrics(true_classes, y_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           a       1.00      0.76      0.87        17\n",
            "          ba       0.88      0.82      0.85        17\n",
            "          ca       0.80      0.94      0.86        17\n",
            "          da       1.00      0.82      0.90        17\n",
            "          ga       0.89      1.00      0.94        16\n",
            "          ja       0.81      1.00      0.89        17\n",
            "          ka       0.94      1.00      0.97        17\n",
            "          la       1.00      0.88      0.94        17\n",
            "          ma       0.94      0.94      0.94        17\n",
            "          na       0.84      0.94      0.89        17\n",
            "         nga       1.00      0.82      0.90        17\n",
            "         nya       0.83      0.88      0.86        17\n",
            "          pa       0.74      1.00      0.85        17\n",
            "          ra       0.94      0.94      0.94        17\n",
            "          sa       1.00      0.76      0.87        17\n",
            "          ta       0.93      0.82      0.87        17\n",
            "          wa       0.94      0.88      0.91        17\n",
            "          ya       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.90       305\n",
            "   macro avg       0.91      0.90      0.90       305\n",
            "weighted avg       0.91      0.90      0.90       305\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "clr = classification_report(true_classes, y_predictions,\n",
        "                            labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \n",
        "                            target_names=['a', 'ba','ca','da','ga','ja','ka','la','ma','na','nga','nya','pa','ra','sa','ta','wa','ya'])\n",
        "print(clr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_FILENAME = root_path+\"modelpengujian13_3x3_arsitektur2.h5\"\n",
        "model.save(MODEL_FILENAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "24dc7b20f56b03d1f16e6cc38505b58c26a9c0d2aa82b50d0cbd183a5ef7f314"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
